{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpp_tensorflow.config import get_params_semisparse, get_params_sparse, parser\n",
    "from tpp_tensorflow.datautils import get_tfrecords_input_fn\n",
    "from tpp_tensorflow.models.semisparse import SemiSparseInput\n",
    "from tpp_tensorflow.models.sparse import SparseInput\n",
    "from tpp_tensorflow.models.dense import DenseHead\n",
    "from tpp_tensorflow.utils import compute_mean_auc_fold, print_config, export_run_logs\n",
    "\n",
    "from tpp_tensorflow.steps import train_step, eval_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_PORT = 6711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TYPE = \"semisparse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_DISK0 = Path(\"/local00/bioinf/tpp/\")\n",
    "DATA_ROOT_DISK1 = Path(\"/local01/bioinf/tpp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = (DATA_ROOT_DISK0 / \"models\").as_posix()\n",
    "RUN_LOG_DIR = (DATA_ROOT_DISK0 / \"run_logs\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDS_TRAIN = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/train.tfrecords\").as_posix()\n",
    "RECORDS_TEST = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/test.tfrecords\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_MASK_TRAIN_PATH = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/label_mask_train.parquet/\").as_posix()\n",
    "AUC_MASK_TEST_PATH = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/label_mask_test.parquet/\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_ASSAYS_MASK_PATH = Path(\"/publicdata/tpp/runs/thesis_chembl25/common_assays_mask.parquet\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/metadata.json\", \"r\") as infile:\n",
    "    metadata = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_size': 2193,\n",
       " 'CATS2D_clean_size': 29,\n",
       " 'SHED_clean_size': 3,\n",
       " 'num_items_test': 189716,\n",
       " 'num_items_train': 397969}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somewhat arbitrary number < nitems for train / val split\n",
    "TRAIN_SET_SIZE = int(metadata[\"num_items_train\"] * 0.6)\n",
    "NUM_CLASSES = metadata[\"labels_size\"]\n",
    "\n",
    "if FEATURE_TYPE == \"semisparse\":\n",
    "    CATS2D_SIZE = metadata[\"CATS2D_clean_size\"]\n",
    "    SHED_SIZE = metadata[\"SHED_clean_size\"]\n",
    "    \n",
    "    custom_args = f\"\"\"\n",
    "    --cats2d-size {CATS2D_SIZE} --shed-size {SHED_SIZE} \n",
    "    \"\"\"\n",
    "    \n",
    "elif FEATURE_TYPE == \"sparse\":\n",
    "    DFS8_SIZE = metadata[\"DFS8_clean_size\"]\n",
    "    ECFC4_SIZE = metadata[\"ECFC4_clean_size\"]\n",
    "    ECFC6_SIZE = metadata[\"ECFC6_clean_size\"]\n",
    "    \n",
    "    FEATURE = \"dfs8\"\n",
    "    FEATURE_SIZE = DFS8_SIZE\n",
    "    EMBEDDING_SIZE = 2048\n",
    "    \n",
    "    custom_args = f\"\"\"\n",
    "    --feature {FEATURE} --feature-size {FEATURE_SIZE} --embedding-size {EMBEDDING_SIZE} \n",
    "    --ecfc4-size {ECFC4_SIZE} --ecfc6-size {ECFC6_SIZE} --dfs8-size {DFS8_SIZE} \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238781"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "DROPOUT_RATE = 0.4\n",
    "INPUT_DROPOUT_RATE = 0.2\n",
    "ACTIVATION = \"selu\"\n",
    "REG_L2_RATE = 0.01\n",
    "LR = 0.1\n",
    "LR_DECAY_STEPS = 500000\n",
    "LR_DECAY_RATE = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args((f\"\"\"\n",
    "    {FEATURE_TYPE} \n",
    "    --model-dir {MODEL_DIR} \n",
    "    --run-log-dir {RUN_LOG_DIR} \n",
    "    --records-train {RECORDS_TRAIN} \n",
    "    --records-test {RECORDS_TEST} \n",
    "    --auc-mask-train-path {AUC_MASK_TRAIN_PATH} \n",
    "    --auc-mask-test-path {AUC_MASK_TEST_PATH} \n",
    "    --common-assays-mask-path {COMMON_ASSAYS_MASK_PATH} \n",
    "    --num-epochs {NUM_EPOCHS} --batch-size {BATCH_SIZE} --dropout-rate {DROPOUT_RATE} \n",
    "    --lr {LR} --lr-decay-steps {LR_DECAY_STEPS} --lr-decay-rate {LR_DECAY_RATE}\n",
    "    --input-dropout-rate {INPUT_DROPOUT_RATE} --activation {ACTIVATION} --reg-l2-rate {REG_L2_RATE}\n",
    "    --train-set-size {TRAIN_SET_SIZE} \n",
    "    \"\"\" + custom_args).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = get_tfrecords_input_fn(args.run_type)\n",
    "get_params = get_params_semisparse if args.run_type == \"semisparse\" else get_params_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arg Namespace to NamedTuple for autocomplete in IDE / Jupyter\n",
    "rparam, hparam = get_params(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = input_fn(rparam.records_train, mode=\"train\", cache=True, split_train_eval=True, train_set_size=rparam.train_set_size, num_epochs=1, batch_size=hparam.batch_size, shuffle=True, rparams=rparam)\n",
    "val_ds = input_fn(rparam.records_train, mode=\"eval\", cache=True, split_train_eval=True, train_set_size=rparam.train_set_size, num_epochs=1, batch_size=hparam.batch_size, rparams=rparam)\n",
    "\n",
    "train_ds_auc = input_fn(rparam.records_train, mode=\"train\", cache=True, split_train_eval=True, train_set_size=rparam.train_set_size, num_epochs=1, batch_size=hparam.batch_size, rparams=rparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model = SemiSparseInput(hparam) if args.run_type == \"semisparse\" else SparseInput(hparam)\n",
    "output_model = DenseHead(hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (input_model, output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(hparam.lr, hparam.lr_decay_steps, hparam.lr_decay_rate, staircase=True)\n",
    "optimizer = tf.keras.optimizers.SGD(lr=hparam.lr)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Accuracy(name='train_accuracy')\n",
    "train_metrics = (train_loss, train_accuracy)\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.Accuracy(name='val_accuracy')\n",
    "val_metrics = (val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = Path(rparam.model_dir) / \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir $logdir --port 6711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = rparam.run_id\n",
    "\n",
    "train_log_dir = logdir / \"train\"\n",
    "val_log_dir = logdir / \"val\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir.as_posix())\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_dir.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask_train = pd.read_parquet(rparam.auc_mask_train_path).key.values\n",
    "label_mask_val = pd.read_parquet(rparam.auc_mask_train_path).key.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.32434, Accuracy: 0.86412, meanAUC: 0.53704286, Val Loss: 0.29737, Val Accuracy: 0.87284, Val meanAUC: 0.52347714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-29-8596fee39612>\", line 5, in <module>\n",
      "    train_step(features, labels, models, train_metrics, optimizer, hparam)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 487, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1823, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1141, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/system/user/ruch/miniconda3/envs/tpp_tf_v2.0.0_py3.7/lib/python3.7/posixpath.py\", line 431, in _joinrealpath\n",
      "    continue\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for epoch in range(hparam.num_epochs):\n",
    "    for features, labels in train_ds:        \n",
    "        optimizer.learning_rate = lr_scheduler(global_step)\n",
    "        train_step(features, labels, models, train_metrics, optimizer, hparam)\n",
    "        global_step += 1\n",
    "        \n",
    "    train_mean_auc, _ = compute_mean_auc_fold(models, train_ds_auc, eval_step, hparam, label_mask_train)\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "        tf.summary.scalar(\"mean_auc\", train_mean_auc, step=epoch)\n",
    "\n",
    "    for features, labels in val_ds:\n",
    "        eval_step(features, labels, models, val_metrics, hparam)\n",
    "        \n",
    "    val_mean_auc, _ = compute_mean_auc_fold(models, val_ds, eval_step, hparam, label_mask_val)\n",
    "    \n",
    "    with val_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', val_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', val_accuracy.result(), step=epoch)\n",
    "        tf.summary.scalar(\"mean_auc\", val_mean_auc, step=epoch)\n",
    "        \n",
    "    template = 'Epoch {0}, Loss: {1:.5g}, Accuracy: {2:.5g}, meanAUC: {3:.8g}, Val Loss: {4:.5g}, Val Accuracy: {5:.5g}, Val meanAUC: {6:.8g}'\n",
    "    print(template.format(\n",
    "        epoch,\n",
    "        train_loss.result(),\n",
    "        train_accuracy.result(),\n",
    "        train_mean_auc,\n",
    "        val_loss.result(),\n",
    "        val_accuracy.result(),\n",
    "        val_mean_auc))\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_run_logs(args.run_type, args.run_log_dir, rparam, hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask_test = pd.read_parquet(rparam.auc_mask_test_path).key.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_assays_mask = pd.read_parquet(rparam.common_assays_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask_test = set(label_mask_test) & set(np.nonzero(common_assays_mask.assay_id.values)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = input_fn(rparam.records_test, mode=\"eval\", cache=False, split_train_eval=False, num_epochs=1, batch_size=hparam.batch_size, rparams=rparam)\n",
    "test_mean_auc, _ = compute_mean_auc_fold(models, test_ds, eval_step, hparam, label_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test meanAUC: 0.526199460029602\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test meanAUC: {test_mean_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
