{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpp_tensorflow.config import get_params_semisparse, get_params_sparse, parser\n",
    "from tpp_tensorflow.datautils import get_tfrecords_input_fn\n",
    "from tpp_tensorflow.models.semisparse import SemiSparseInput\n",
    "from tpp_tensorflow.models.sparse import SparseInput\n",
    "from tpp_tensorflow.models.dense import DenseHead\n",
    "from tpp_tensorflow.utils import compute_mean_auc_fold, print_config, export_run_logs\n",
    "\n",
    "from tpp_tensorflow.steps import train_step, eval_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_PORT = 6711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TYPE = \"semisparse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_DISK0 = Path(\"/local00/bioinf/tpp/\")\n",
    "DATA_ROOT_DISK1 = Path(\"/local01/bioinf/tpp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = (DATA_ROOT_DISK0 / \"models\").as_posix()\n",
    "RUN_LOG_DIR = (DATA_ROOT_DISK0 / \"run_logs\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDS_TRAIN = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/train.tfrecords\").as_posix()\n",
    "RECORDS_TEST = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/test.tfrecords\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_MASK_TRAIN_PATH = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/label_mask_train.parquet/\").as_posix()\n",
    "AUC_MASK_TEST_PATH = (DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/label_mask_test.parquet/\").as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_ROOT_DISK1 / f\"runs/thesis_chembl25/records_{FEATURE_TYPE}/metadata.json\", \"r\") as infile:\n",
    "    metadata = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somewhat arbitrary number < nitems for train / val split\n",
    "TRAIN_SET_SIZE = int(metadata[\"num_items_train\"] * 0.6)\n",
    "NUM_CLASSES = metadata[\"labels_size\"]\n",
    "\n",
    "if FEATURE_TYPE == \"semisparse\":\n",
    "    CATS2D_SIZE = metadata[\"CATS2D_clean_size\"]\n",
    "    SHED_SIZE = metadata[\"SHED_clean_size\"]\n",
    "    \n",
    "    custom_args = f\"\"\"\n",
    "    --cats2d-size {CATS2D_SIZE} --shed-size {SHED_SIZE} \n",
    "    \"\"\"\n",
    "    \n",
    "elif FEATURE_TYPE == \"sparse\":\n",
    "    DFS8_SIZE = metadata[\"DFS8_clean_size\"]\n",
    "    ECFC4_SIZE = metadata[\"ECFC4_clean_size\"]\n",
    "    ECFC6_SIZE = metadata[\"ECFC6_clean_size\"]\n",
    "    \n",
    "    FEATURE = \"dfs8\"\n",
    "    FEATURE_SIZE = DFS8_SIZE\n",
    "    EMBEDDING_SIZE = 2048\n",
    "    \n",
    "    custom_args = f\"\"\"\n",
    "    --feature {FEATURE} --feature-size {FEATURE_SIZE} --embedding-size {EMBEDDING_SIZE} \n",
    "    --ecfc4-size {ECFC4_SIZE} --ecfc6-size {ECFC6_SIZE} --dfs8-size {DFS8_SIZE} \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 150\n",
    "BATCH_SIZE = 64\n",
    "DROPOUT_RATE = 0.4\n",
    "INPUT_DROPOUT_RATE = 0.2\n",
    "ACTIVATION = \"selu\"\n",
    "REG_L2_RATE = 0.01\n",
    "LR = 0.1\n",
    "LR_DECAY_STEPS = 500000\n",
    "LR_DECAY_RATE = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args((f\"\"\"\n",
    "    {FEATURE_TYPE} \n",
    "    --model-dir {MODEL_DIR} \n",
    "    --run-log-dir {RUN_LOG_DIR} \n",
    "    --records-train {RECORDS_TRAIN} \n",
    "    --records-test {RECORDS_TEST} \n",
    "    --auc-mask-train-path {AUC_MASK_TRAIN_PATH} \n",
    "    --auc-mask-test-path {AUC_MASK_TEST_PATH} \n",
    "    --num-epochs {NUM_EPOCHS} --batch-size {BATCH_SIZE} --dropout-rate {DROPOUT_RATE} \n",
    "    --lr {LR} --lr-decay-steps {LR_DECAY_STEPS} --lr-decay-rate {LR_DECAY_RATE}\n",
    "    --input-dropout-rate {INPUT_DROPOUT_RATE} --activation {ACTIVATION} --reg-l2-rate {REG_L2_RATE}\n",
    "    --train-set-size {TRAIN_SET_SIZE} \n",
    "    \"\"\" + custom_args).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = get_tfrecords_input_fn(args.run_type)\n",
    "get_params = get_params_semisparse if args.run_type == \"semisparse\" else get_params_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arg Namespace to NamedTuple for autocomplete in IDE / Jupyter\n",
    "rparam, hparam = get_params(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = input_fn(rparam.records_train, mode=\"train\", cache=True, split_train_eval=True, train_set_size=rparam.train_set_size, num_epochs=1, batch_size=hparam.batch_size, shuffle=True, rparams=rparam)\n",
    "val_ds = input_fn(rparam.records_train, mode=\"eval\", cache=True, split_train_eval=True, train_set_size=rparam.train_set_size, num_epochs=1, batch_size=hparam.batch_size, rparams=rparam)\n",
    "\n",
    "train_ds_auc = input_fn(rparam.records_train, mode=\"train\", cache=True, split_train_eval=True, train_set_size=rparam.train_set_size, num_epochs=1, batch_size=hparam.batch_size, rparams=rparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model = SemiSparseInput(hparam) if args.run_type == \"semisparse\" else SparseInput(hparam)\n",
    "output_model = DenseHead(hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (input_model, output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(hparam.lr, hparam.lr_decay_steps, hparam.lr_decay_rate, staircase=True)\n",
    "optimizer = tf.keras.optimizers.SGD(lr=hparam.lr)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Accuracy(name='train_accuracy')\n",
    "train_metrics = (train_loss, train_accuracy)\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.Accuracy(name='val_accuracy')\n",
    "val_metrics = (val_loss, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = Path(rparam.model_dir) / \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir $logdir --port 6711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = rparam.run_id\n",
    "\n",
    "train_log_dir = logdir / \"train\"\n",
    "val_log_dir = logdir / \"val\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir.as_posix())\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_dir.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask_train = pd.read_parquet(rparam.auc_mask_train_path).key.values\n",
    "label_mask_val = pd.read_parquet(rparam.auc_mask_train_path).key.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "for epoch in range(hparam.num_epochs):\n",
    "    for features, labels in train_ds:        \n",
    "        optimizer.learning_rate = lr_scheduler(global_step)\n",
    "        train_step(features, labels, models, train_metrics, optimizer, hparam)\n",
    "        global_step += 1\n",
    "        \n",
    "    train_mean_auc, _ = compute_mean_auc_fold(models, train_ds_auc, eval_step, hparam, label_mask_train)\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "        tf.summary.scalar(\"mean_auc\", train_mean_auc, step=epoch)\n",
    "\n",
    "    for features, labels in val_ds:\n",
    "        eval_step(features, labels, models, val_metrics, hparam)\n",
    "        \n",
    "    val_mean_auc, _ = compute_mean_auc_fold(models, val_ds, eval_step, hparam, label_mask_val)\n",
    "    \n",
    "    with val_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', val_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', val_accuracy.result(), step=epoch)\n",
    "        tf.summary.scalar(\"mean_auc\", val_mean_auc, step=epoch)\n",
    "        \n",
    "    template = 'Epoch {0}, Loss: {1:.5g}, Accuracy: {2:.5g}, meanAUC: {3:.8g}, Val Loss: {4:.5g}, Val Accuracy: {5:.5g}, Val meanAUC: {6:.8g}'\n",
    "    print(template.format(\n",
    "        epoch,\n",
    "        train_loss.result(),\n",
    "        train_accuracy.result(),\n",
    "        train_mean_auc,\n",
    "        val_loss.result(),\n",
    "        val_accuracy.result(),\n",
    "        val_mean_auc))\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    val_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    val_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(rparam.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_run_logs(args.run_type, args.run_log_dir, rparam, hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask_test = pd.read_parquet(rparam.auc_mask_test_path).key.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_assays_mask = pd.read_parquet(\"/publicdata/tpp/runs/thesis_chembl25/common_assays_mask.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask_test = set(label_mask_test) & set(np.nonzero(common_assays_mask.assay_id.values)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = input_fn(rparam.records_test, mode=\"eval\", cache=False, split_train_eval=False, num_epochs=1, batch_size=hparam.batch_size, rparams=rparam)\n",
    "test_mean_auc, _ = compute_mean_auc_fold(models, test_ds, eval_step, hparam, label_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test meanAUC: {test_mean_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
